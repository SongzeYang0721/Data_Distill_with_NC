{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc62cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9cd010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257c8748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10, MNIST\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import copy\n",
    "from contextlib import contextmanager\n",
    "\n",
    "from six import add_metaclass\n",
    "from typing import Type, Any, Callable, Union, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d55d014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744891f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "from models.resnet import ResNet, BasicBlock\n",
    "from utils import *\n",
    "from train_2nd_order import weight_decay, trainer\n",
    "from validate_NC import compute_Wh_b_relation, compute_W_H_relation, compute_ETF, compute_Sigma_B, compute_Sigma_W,compute_info,FCFeatures\n",
    "from datasets import make_dataset\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import scipy.linalg as scilin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eec391e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f8486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture params\n",
    "model='resnet18'\n",
    "\n",
    "# dataset\n",
    "dataset='mnist'\n",
    "data_dir='~/data'\n",
    "\n",
    "# training params\n",
    "epochs = 1\n",
    "optimizer=\"LBFGS\"\n",
    "lr=0.1\n",
    "history_size=10\n",
    "batch_size=1024\n",
    "uid=\"tmp4\"\n",
    "device = \"cpu\"\n",
    "SOTA=False\n",
    "\n",
    "# Network params\n",
    "loss = 'CrossEntropy'\n",
    "bias=True\n",
    "ETF_fc=False\n",
    "fixdim=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1964320",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    def __init__(self, model='resnet18', bias=True, ETF_fc=False, fixdim=0, SOTA=False,\n",
    "                 width=1024, depth=6, gpu_id=0, seed=6, use_cudnn=True,\n",
    "                 dataset='mnist', data_dir='~/data', uid=None, force=False,\n",
    "                 epochs=200, batch_size=1024, loss='CrossEntropy', sample_size=None,\n",
    "                 lr=0.1, patience=40, decay_type='step', gamma = 0.1, optimizer='SGD',\n",
    "                 weight_decay=5e-4, sep_decay=False, feature_decay_rate=1e-4,\n",
    "                 history_size=10, ghost_batch=128, device = \"cpu\",\n",
    "                 \n",
    "                 # distill setting\n",
    "                 distill_steps=10,\n",
    "                 distill_epochs=3,\n",
    "                 distilled_images_per_class_per_step=1,\n",
    "                 num_classes = None,\n",
    "                 distill_lr = 0.02,\n",
    "                 decay_epochs = 40,\n",
    "                 decay_factor = 0.5\n",
    "                ):\n",
    "\n",
    "        self.model = model\n",
    "        self.bias = bias\n",
    "        self.ETF_fc = ETF_fc\n",
    "        self.fixdim = fixdim\n",
    "        self.SOTA = SOTA\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.gpu_id = gpu_id\n",
    "        self.seed = seed\n",
    "        self.use_cudnn = use_cudnn\n",
    "        self.dataset = dataset\n",
    "        self.data_dir = data_dir\n",
    "        self.uid = uid\n",
    "        self.force = force\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.loss = loss\n",
    "        self.sample_size = sample_size\n",
    "        self.lr = lr\n",
    "        self.patience = patience\n",
    "        self.decay_type = decay_type\n",
    "        self.gamma = gamma\n",
    "        self.optimizer = optimizer\n",
    "        self.weight_decay = weight_decay\n",
    "        self.sep_decay = sep_decay\n",
    "        self.feature_decay_rate = feature_decay_rate\n",
    "        self.history_size = history_size\n",
    "        self.ghost_batch = ghost_batch\n",
    "        self.device = device\n",
    "        \n",
    "        # distill setting\n",
    "        self.distill_steps = distill_steps\n",
    "        self.distill_epochs = distill_epochs\n",
    "        self.num_classes = num_classes\n",
    "        self.distilled_images_per_class_per_step = distilled_images_per_class_per_step\n",
    "        self.distill_lr = distill_lr\n",
    "        self.decay_epochs = decay_epochs,\n",
    "        self.decay_factor = decay_factor\n",
    "        \n",
    "        if self.uid is None:\n",
    "            unique_id = str(np.random.randint(0, 100000))\n",
    "            print(\"revise the unique id to a random number \" + str(unique_id))\n",
    "            self.uid = unique_id\n",
    "            timestamp = datetime.datetime.now().strftime(\"%a-%b-%d-%H-%M\")\n",
    "            save_path = './model_weights/' + self.uid + '-' + timestamp\n",
    "        else:\n",
    "            save_path = './model_weights/' + str(self.uid)\n",
    "        \n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "        else:\n",
    "            if not self.force:\n",
    "                raise (\"please use another uid \")\n",
    "            else:\n",
    "                print(\"override this uid\" + self.uid)\n",
    "                for m in range(1, 10):\n",
    "#                     print(os.path.exists(save_path + \"/log.txt.bk\" + str(m)))\n",
    "                    if not os.path.exists(save_path + \"/log.txt.bk\" + str(m)):\n",
    "                        shutil.copy(save_path + \"/log.txt\", save_path + \"/log.txt.bk\" + str(m))\n",
    "                        shutil.copy(save_path + \"/args.txt\", save_path + \"/args.txt.bk\" + str(m))\n",
    "                        break\n",
    "        self.save_path = save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d529de",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = args(model=model, dataset=dataset, optimizer=optimizer, lr = lr, loss = loss,\n",
    "            history_size=history_size, batch_size = batch_size, epochs=1,\n",
    "            uid = uid, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9056f1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee22000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader, num_classes = make_dataset(dataset, \n",
    "                                           data_dir, \n",
    "                                           batch_size, \n",
    "                                           SOTA=SOTA)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b2bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "size_train, channels, height, width = images.shape\n",
    "num_classes = len(torch.unique(labels))\n",
    "nc = channels\n",
    "input_size = height, width\n",
    "print(\"The number of class in our training set is \", num_classes)\n",
    "print(\"Batch size:\", size_train, \"Number of channels:\", channels, \"input height:\", height, \"input width:\", width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162099ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07834d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121a6431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
